window.__LLM_FAMILIES__ = [
  {
    "family": "GPT Series",
    "steward": "OpenAI",
    "license": "Closed / Hosted",
    "initial_release": "2020 (GPT‑3)",
    "current_release": "2025 (GPT‑4o / 4.1)",
    "modalities": [
      "Text",
      "Vision",
      "Audio"
    ],
    "context_window": "128k – ~1M tokens",
    "traits": [
      "Omni I/O",
      "Generalist",
      "Wide ecosystem"
    ],
    "links": [
      {
        "label": "Model overview",
        "url": "#"
      }
    ]
  },
  {
    "family": "Claude Family",
    "steward": "Anthropic",
    "license": "Closed / Hosted",
    "initial_release": "2023 (Claude 1)",
    "current_release": "2024 (Claude 3)",
    "modalities": [
      "Text",
      "Vision"
    ],
    "context_window": "200k – ~1M tokens",
    "traits": [
      "Constitutional AI",
      "Reasoning",
      "Safety docs"
    ],
    "links": [
      {
        "label": "Docs",
        "url": "#"
      }
    ]
  },
  {
    "family": "Gemini / Gemma",
    "steward": "Google DeepMind",
    "license": "Mixed (Gemini closed, Gemma open)",
    "initial_release": "2022 (PaLM)",
    "current_release": "2025 (Gemini 1.5 / 2.x)",
    "modalities": [
      "Text",
      "Vision",
      "Audio"
    ],
    "context_window": "Up to ~1M tokens",
    "traits": [
      "Native multimodal reasoning"
    ],
    "links": [
      {
        "label": "Model card",
        "url": "#"
      }
    ]
  },
  {
    "family": "Llama Family",
    "steward": "Meta",
    "license": "Open‑weight (custom)",
    "initial_release": "2023 (Llama 1)",
    "current_release": "2024 (Llama 3 / 3.1)",
    "modalities": [
      "Text",
      "Vision"
    ],
    "context_window": "Up to 128k tokens",
    "traits": [
      "Open ecosystem",
      "Many sizes"
    ],
    "links": [
      {
        "label": "License",
        "url": "#"
      }
    ]
  },
  {
    "family": "Mistral / Mixtral / Codestral",
    "steward": "Mistral AI",
    "license": "Open‑weight & Hosted",
    "initial_release": "2023 (Mistral 7B)",
    "current_release": "2025 (Codestral / Voxtral)",
    "modalities": [
      "Text",
      "Code",
      "Audio"
    ],
    "context_window": "32k – 128k tokens",
    "traits": [
      "Efficient MoE",
      "Code‑strong"
    ],
    "links": [
      {
        "label": "Portal",
        "url": "#"
      }
    ]
  },
  {
    "family": "Grok Family",
    "steward": "xAI",
    "license": "Closed / Hosted",
    "initial_release": "2023 (Grok)",
    "current_release": "2025 (Grok 4 / 4 Fast)",
    "modalities": [
      "Text",
      "Vision"
    ],
    "context_window": "Up to ~256k tokens",
    "traits": [
      "Real‑time search",
      "Large context"
    ],
    "links": [
      {
        "label": "Overview",
        "url": "#"
      }
    ]
  },
  {
    "family": "DBRX",
    "steward": "Databricks",
    "license": "Open‑weight & Hosted",
    "initial_release": "2024 (DBRX)",
    "current_release": "2024 (DBRX)",
    "modalities": [
      "Text",
      "Code"
    ],
    "context_window": "Up to 64k tokens",
    "traits": [
      "Enterprise MoE",
      "Lakehouse native"
    ],
    "links": [
      {
        "label": "Blog",
        "url": "#"
      }
    ]
  },
  {
    "family": "Qwen Family",
    "steward": "Alibaba (Qwen)",
    "license": "Open‑weight & Hosted",
    "initial_release": "2023 (Qwen)",
    "current_release": "2025 (Qwen 3; incl. VL)",
    "modalities": [
      "Text",
      "Vision",
      "Audio"
    ],
    "context_window": "Up to 128k tokens",
    "traits": [
      "Multilingual",
      "Vision variants"
    ],
    "links": [
      {
        "label": "Repo",
        "url": "#"
      }
    ]
  },
  {
    "family": "Command Family",
    "steward": "Cohere",
    "license": "Closed / Hosted",
    "initial_release": "2024 (Command R / R+)",
    "current_release": "2025 (Command A line)",
    "modalities": [
      "Text",
      "Embeddings"
    ],
    "context_window": "Up to 128k tokens",
    "traits": [
      "RAG‑friendly",
      "Agents"
    ],
    "links": [
      {
        "label": "Docs",
        "url": "#"
      }
    ]
  },
  {
    "family": "Jamba",
    "steward": "AI21 Labs",
    "license": "Open‑weight & Hosted",
    "initial_release": "2024 (Jamba)",
    "current_release": "2025 (Jamba 1.6)",
    "modalities": [
      "Text"
    ],
    "context_window": "Up to 256k tokens",
    "traits": [
      "SSM + Transformer hybrid"
    ],
    "links": [
      {
        "label": "Paper",
        "url": "#"
      }
    ]
  },
  {
    "family": "BLOOM",
    "steward": "BigScience / HF",
    "license": "Open",
    "initial_release": "2022 (BLOOM)",
    "current_release": "2022 (BLOOM)",
    "modalities": [
      "Text"
    ],
    "context_window": "4k tokens",
    "traits": [
      "Multilingual research"
    ],
    "links": [
      {
        "label": "HF page",
        "url": "#"
      }
    ]
  },
  {
    "family": "Phi Family",
    "steward": "Microsoft Research",
    "license": "Open‑weight",
    "initial_release": "2024 (Phi‑2)",
    "current_release": "2025 (Phi‑3)",
    "modalities": [
      "Text",
      "Code"
    ],
    "context_window": "Up to 128k tokens",
    "traits": [
      "Compact",
      "Efficient"
    ],
    "links": [
      {
        "label": "Paper",
        "url": "#"
      }
    ]
  },
  {
    "family": "Yi Family",
    "steward": "01.AI",
    "license": "Open‑weight",
    "initial_release": "2023 (Yi‑1)",
    "current_release": "2025 (Yi‑1.6)",
    "modalities": [
      "Text",
      "Vision"
    ],
    "context_window": "Up to 128k tokens",
    "traits": [
      "Bilingual (ZH/EN)"
    ],
    "links": [
      {
        "label": "Repo",
        "url": "#"
      }
    ]
  }
];
window.__LLM_TIMELINE__ = [
  {
    "phase": "2018–2019",
    "event": "BERT popularizes bidirectional pretraining",
    "why": "Pretrain‑then‑adapt pattern for NLP."
  },
  {
    "phase": "2020",
    "event": "GPT‑3 demonstrates few‑shot prompting",
    "why": "Shift from fine‑tuning to prompting."
  },
  {
    "phase": "2021",
    "event": "Codex, DALL·E arrive",
    "why": "Code and image generation foundations."
  },
  {
    "phase": "2022",
    "event": "PaLM scales; BLOOM released openly",
    "why": "Scaling + open collaboration push."
  },
  {
    "phase": "2023",
    "event": "Llama 1, Claude 1, GPT‑4",
    "why": "Open‑weight movement, stronger reasoning."
  },
  {
    "phase": "2024",
    "event": "Llama 3, Claude 3, Gemini 1.5, DBRX, Jamba",
    "why": "Long context, MoE/SSM hybrids, multimodality."
  },
  {
    "phase": "2025",
    "event": "GPT‑4.1, Grok 4, Gemini 2.x, Codestral / Qwen3",
    "why": "Reasoning modes, >1M token contexts."
  }
];
